{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import TextClassifierPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsReader(DatasetReader):\n",
    "    def text_to_instance(self, sentence: str, label: int = None) -> Instance:\n",
    "        if not isinstance(sentence, list):\n",
    "            sentence = sentence.split()\n",
    "        \n",
    "        sentence_field = TextField([Token(word) for word in sentence], {\"tokens\": SingleIdTokenIndexer()})\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        if label is not None:\n",
    "            label_field = LabelField(label=label, skip_indexing=True)\n",
    "            fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        text_path = file_path + '.text'\n",
    "        labels_path = file_path + '.labels'\n",
    "        \n",
    "        with open(text_path) as text_f, open(labels_path) as labels_f:\n",
    "            for line_t, line_l in zip(text_f, labels_f):\n",
    "                sentence = line_t.strip()\n",
    "                label = int(line_l.strip())\n",
    "                yield self.text_to_instance(sentence, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266051it [00:13, 20256.82it/s]\n",
      "57011it [00:08, 6536.81it/s] \n",
      "57012it [00:01, 51277.39it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/fursovia/Documents/texar/examples/text_style_transfer/data/insurance_cropped/'\n",
    "reader = InsReader()\n",
    "\n",
    "train_dataset = reader.read(data_path + 'insurance.train')\n",
    "dev_dataset = reader.read(data_path + 'insurance.dev')\n",
    "test_dataset = reader.read(data_path + 'insurance.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323062/323062 [00:01<00:00, 167660.77it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=64)\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models.basic_classifier import BasicClassifier\n",
    "from allennlp.modules.seq2vec_encoders import BagOfEmbeddingsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 16\n",
    "\n",
    "token_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "    embedding_dim=EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "body = BagOfEmbeddingsEncoder(embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicClassifier(\n",
    "    vocab=vocab, \n",
    "    text_field_embedder=word_embeddings, \n",
    "    seq2vec_encoder=body,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicClassifier(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2vec_encoder): BagOfEmbeddingsEncoder()\n",
       "  (_classification_layer): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=dev_dataset,\n",
    "    patience=3,\n",
    "    num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4158 [00:00<?, ?it/s]\u001b[A\n",
      "accuracy: 0.0469, loss: 0.7359 ||:   0%|          | 1/4158 [00:00<32:26,  2.14it/s]\u001b[A\n",
      "accuracy: 0.2168, loss: 0.7138 ||:   0%|          | 8/4158 [00:00<22:58,  3.01it/s]\u001b[A\n",
      "accuracy: 0.4023, loss: 0.6881 ||:   0%|          | 16/4158 [00:00<16:20,  4.23it/s]\u001b[A\n",
      "accuracy: 0.5787, loss: 0.6544 ||:   1%|          | 26/4158 [00:00<11:37,  5.92it/s]\u001b[A\n",
      "accuracy: 0.6759, loss: 0.6228 ||:   1%|          | 35/4158 [00:00<08:21,  8.22it/s]\u001b[A\n",
      "accuracy: 0.7480, loss: 0.5856 ||:   1%|          | 46/4158 [00:00<06:02, 11.36it/s]\u001b[A\n",
      "accuracy: 0.7855, loss: 0.5567 ||:   1%|▏         | 55/4158 [00:01<04:27, 15.35it/s]\u001b[A\n",
      "accuracy: 0.8156, loss: 0.5265 ||:   2%|▏         | 65/4158 [00:01<03:18, 20.57it/s]\u001b[A\n",
      "accuracy: 0.8387, loss: 0.4982 ||:   2%|▏         | 75/4158 [00:01<02:31, 26.90it/s]\u001b[A\n",
      "accuracy: 0.8559, loss: 0.4731 ||:   2%|▏         | 85/4158 [00:01<01:59, 34.18it/s]\u001b[A\n",
      "accuracy: 0.8685, loss: 0.4529 ||:   2%|▏         | 94/4158 [00:01<01:36, 41.94it/s]\u001b[A\n",
      "accuracy: 0.8786, loss: 0.4337 ||:   2%|▏         | 103/4158 [00:01<01:25, 47.66it/s]\u001b[A\n",
      "accuracy: 0.8873, loss: 0.4179 ||:   3%|▎         | 112/4158 [00:01<01:14, 54.37it/s]\u001b[A\n",
      "accuracy: 0.8956, loss: 0.4001 ||:   3%|▎         | 122/4158 [00:01<01:04, 62.16it/s]\u001b[A\n",
      "accuracy: 0.9023, loss: 0.3862 ||:   3%|▎         | 132/4158 [00:01<00:57, 70.08it/s]\u001b[A\n",
      "accuracy: 0.9082, loss: 0.3729 ||:   3%|▎         | 142/4158 [00:02<00:52, 76.84it/s]\u001b[A\n",
      "accuracy: 0.9137, loss: 0.3601 ||:   4%|▎         | 153/4158 [00:02<00:48, 82.95it/s]\u001b[A\n",
      "accuracy: 0.9179, loss: 0.3505 ||:   4%|▍         | 163/4158 [00:02<00:45, 87.15it/s]\u001b[A\n",
      "accuracy: 0.9216, loss: 0.3422 ||:   4%|▍         | 173/4158 [00:02<00:45, 88.21it/s]\u001b[A\n",
      "accuracy: 0.9250, loss: 0.3339 ||:   4%|▍         | 183/4158 [00:02<00:47, 83.11it/s]\u001b[A\n",
      "accuracy: 0.9277, loss: 0.3271 ||:   5%|▍         | 192/4158 [00:02<00:47, 84.35it/s]\u001b[A\n",
      "accuracy: 0.9309, loss: 0.3182 ||:   5%|▍         | 203/4158 [00:02<00:44, 89.63it/s]\u001b[A\n",
      "accuracy: 0.9334, loss: 0.3126 ||:   5%|▌         | 214/4158 [00:02<00:42, 93.22it/s]\u001b[A\n",
      "accuracy: 0.9360, loss: 0.3056 ||:   5%|▌         | 225/4158 [00:02<00:41, 95.71it/s]\u001b[A\n",
      "accuracy: 0.9376, loss: 0.3015 ||:   6%|▌         | 235/4158 [00:03<00:40, 96.09it/s]\u001b[A\n",
      "accuracy: 0.9395, loss: 0.2961 ||:   6%|▌         | 245/4158 [00:03<00:41, 94.93it/s]\u001b[A\n",
      "accuracy: 0.9412, loss: 0.2921 ||:   6%|▌         | 255/4158 [00:03<00:40, 95.50it/s]\u001b[A\n",
      "accuracy: 0.9429, loss: 0.2864 ||:   6%|▋         | 265/4158 [00:03<00:40, 95.98it/s]\u001b[A\n",
      "accuracy: 0.9447, loss: 0.2810 ||:   7%|▋         | 276/4158 [00:03<00:39, 99.07it/s]\u001b[A\n",
      "accuracy: 0.9462, loss: 0.2769 ||:   7%|▋         | 287/4158 [00:03<00:38, 99.99it/s]\u001b[A\n",
      "accuracy: 0.9478, loss: 0.2718 ||:   7%|▋         | 298/4158 [00:03<00:39, 98.53it/s]\u001b[A\n",
      "accuracy: 0.9492, loss: 0.2667 ||:   7%|▋         | 308/4158 [00:03<00:40, 95.16it/s]\u001b[A\n",
      "accuracy: 0.9501, loss: 0.2640 ||:   8%|▊         | 318/4158 [00:03<00:41, 92.95it/s]\u001b[A\n",
      "accuracy: 0.9510, loss: 0.2611 ||:   8%|▊         | 328/4158 [00:04<00:41, 91.72it/s]\u001b[A\n",
      "accuracy: 0.9520, loss: 0.2570 ||:   8%|▊         | 338/4158 [00:04<00:41, 91.66it/s]\u001b[A\n",
      "accuracy: 0.9528, loss: 0.2551 ||:   8%|▊         | 348/4158 [00:04<00:42, 90.07it/s]\u001b[A\n",
      "accuracy: 0.9538, loss: 0.2510 ||:   9%|▊         | 358/4158 [00:04<00:42, 90.32it/s]\u001b[A\n",
      "accuracy: 0.9547, loss: 0.2477 ||:   9%|▉         | 369/4158 [00:04<00:40, 93.87it/s]\u001b[A\n",
      "accuracy: 0.9556, loss: 0.2441 ||:   9%|▉         | 380/4158 [00:04<00:38, 97.78it/s]\u001b[A\n",
      "accuracy: 0.9564, loss: 0.2417 ||:   9%|▉         | 390/4158 [00:04<00:39, 94.88it/s]\u001b[A\n",
      "  0%|          | 0/8315 [35:24<?, ?it/s]                                             \n",
      "accuracy: 0.9821, loss: 0.1079 ||: 100%|██████████| 4158/4158 [00:36<00:00, 112.97it/s]\n",
      "accuracy: 0.9851, loss: 0.0759 ||: 100%|██████████| 891/891 [00:03<00:00, 282.47it/s]\n",
      "accuracy: 0.9852, loss: 0.0668 ||: 100%|██████████| 4158/4158 [00:30<00:00, 135.42it/s]\n",
      "accuracy: 0.9852, loss: 0.0654 ||: 100%|██████████| 891/891 [00:02<00:00, 332.92it/s]\n",
      "accuracy: 0.9851, loss: 0.0615 ||: 100%|██████████| 4158/4158 [00:34<00:00, 120.82it/s]\n",
      "accuracy: 0.9852, loss: 0.0648 ||: 100%|██████████| 891/891 [00:02<00:00, 344.62it/s]\n",
      "accuracy: 0.9851, loss: 0.0601 ||: 100%|██████████| 4158/4158 [00:30<00:00, 137.10it/s]\n",
      "accuracy: 0.9850, loss: 0.0650 ||: 100%|██████████| 891/891 [00:02<00:00, 372.16it/s]\n",
      "accuracy: 0.9852, loss: 0.0595 ||: 100%|██████████| 4158/4158 [00:30<00:00, 136.86it/s]\n",
      "accuracy: 0.9848, loss: 0.0650 ||: 100%|██████████| 891/891 [00:02<00:00, 373.97it/s]\n",
      "accuracy: 0.9852, loss: 0.0593 ||: 100%|██████████| 4158/4158 [00:30<00:00, 136.65it/s]\n",
      "accuracy: 0.9845, loss: 0.0656 ||: 100%|██████████| 891/891 [00:02<00:00, 377.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 2,\n",
       " 'peak_cpu_memory_MB': 1576.292352,\n",
       " 'training_duration': '0:02:55.976958',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 4,\n",
       " 'epoch': 4,\n",
       " 'training_accuracy': 0.9852471894486395,\n",
       " 'training_loss': 0.05954500032598247,\n",
       " 'training_cpu_memory_MB': 1576.292352,\n",
       " 'validation_accuracy': 0.984827489431864,\n",
       " 'validation_loss': 0.06498578472343074,\n",
       " 'best_validation_accuracy': 0.9852133798740594,\n",
       " 'best_validation_loss': 0.0647929108724642}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model=model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': [2.871548652648926, -2.553658962249756],\n",
       " 'probs': [0.9956151247024536, 0.004384840372949839],\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"a_2030 a_710 a_1 a_1978 a_1688 a_1737\"\n",
    "predictor.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

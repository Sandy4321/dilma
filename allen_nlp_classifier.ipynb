{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy, Auc\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import TextClassifierPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsReader(DatasetReader):\n",
    "    def text_to_instance(self, sentence: str, label: int = None) -> Instance:\n",
    "        if not isinstance(sentence, list):\n",
    "            sentence = sentence.split()\n",
    "        \n",
    "        sentence_field = TextField([Token(word) for word in sentence], {\"tokens\": SingleIdTokenIndexer()})\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        if label is not None:\n",
    "            label_field = LabelField(label=label, skip_indexing=True)\n",
    "            fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        text_path = file_path + '.text'\n",
    "        labels_path = file_path + '.labels'\n",
    "        \n",
    "        with open(text_path) as text_f, open(labels_path) as labels_f:\n",
    "            for line_t, line_l in zip(text_f, labels_f):\n",
    "                sentence = line_t.strip()\n",
    "                label = int(line_l.strip())\n",
    "                yield self.text_to_instance(sentence, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266051it [00:17, 15091.94it/s]\n",
      "57011it [00:02, 26556.73it/s]\n",
      "57012it [00:03, 16875.45it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/mnt/chatbot_models2/fursov/texar/examples/text_style_transfer/data/insurance_cropped/'\n",
    "reader = InsReader()\n",
    "\n",
    "train_dataset = reader.read(data_path + 'insurance.train')\n",
    "dev_dataset = reader.read(data_path + 'insurance.dev')\n",
    "test_dataset = reader.read(data_path + 'insurance.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323062/323062 [00:03<00:00, 96643.55it/s] \n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=256)\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models.basic_classifier import BasicClassifier\n",
    "from allennlp.modules.seq2vec_encoders import BagOfEmbeddingsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 16\n",
    "\n",
    "token_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "    embedding_dim=EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "body = BagOfEmbeddingsEncoder(embedding_dim=HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(BasicClassifier):\n",
    "    def __init__(self, vocabulary, text_field_embedder, seq2seq_encoder, seq2vec_encoder):\n",
    "        super().__init__(\n",
    "            vocab=vocabulary, \n",
    "            text_field_embedder=text_field_embedder,\n",
    "            seq2vec_encoder=seq2vec_encoder, \n",
    "            seq2seq_encoder=seq2seq_encoder,\n",
    "            num_labels=2\n",
    "        )\n",
    "        self.auc = Auc()\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = super().get_metrics()\n",
    "        metrics.update({\"roc_auc\": self.auc.get_metric(reset)})\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocabulary=vocab, \n",
    "    text_field_embedder=word_embeddings, \n",
    "    seq2seq_encoder=lstm,\n",
    "    seq2vec_encoder=body,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 0\n",
    "model = model.cuda(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2seq_encoder): PytorchSeq2SeqWrapper(\n",
       "    (_module): LSTM(32, 16, batch_first=True)\n",
       "  )\n",
       "  (_seq2vec_encoder): BagOfEmbeddingsEncoder()\n",
       "  (_classification_layer): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=dev_dataset,\n",
    "    patience=3,\n",
    "    num_epochs=10,\n",
    "    cuda_device=cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9836, roc_auc: 0.5000, loss: 0.1131 ||: 100%|██████████| 1040/1040 [00:35<00:00, 29.14it/s]\n",
      "accuracy: 0.9839, roc_auc: 0.5000, loss: 0.0688 ||: 100%|██████████| 223/223 [00:04<00:00, 49.06it/s]\n",
      "accuracy: 0.9844, roc_auc: 0.5000, loss: 0.0646 ||: 100%|██████████| 1040/1040 [00:25<00:00, 40.12it/s]\n",
      "accuracy: 0.9844, roc_auc: 0.5000, loss: 0.0654 ||: 100%|██████████| 223/223 [00:03<00:00, 61.46it/s]\n",
      "accuracy: 0.9846, roc_auc: 0.5000, loss: 0.0605 ||: 100%|██████████| 1040/1040 [00:26<00:00, 39.05it/s]\n",
      "accuracy: 0.9846, roc_auc: 0.5000, loss: 0.0632 ||: 100%|██████████| 223/223 [00:04<00:00, 62.37it/s]\n",
      "accuracy: 0.9848, roc_auc: 0.5000, loss: 0.0588 ||: 100%|██████████| 1040/1040 [00:26<00:00, 38.97it/s]\n",
      "accuracy: 0.9848, roc_auc: 0.5000, loss: 0.0630 ||: 100%|██████████| 223/223 [00:03<00:00, 61.76it/s]\n",
      "accuracy: 0.9849, roc_auc: 0.5000, loss: 0.0572 ||: 100%|██████████| 1040/1040 [00:24<00:00, 41.90it/s]\n",
      "accuracy: 0.9849, roc_auc: 0.5000, loss: 0.0636 ||: 100%|██████████| 223/223 [00:03<00:00, 64.40it/s]\n",
      "accuracy: 0.9850, roc_auc: 0.5000, loss: 0.0563 ||: 100%|██████████| 1040/1040 [00:25<00:00, 41.56it/s]\n",
      "accuracy: 0.9850, roc_auc: 0.5000, loss: 0.0639 ||: 100%|██████████| 223/223 [00:03<00:00, 57.66it/s]\n",
      "accuracy: 0.9851, roc_auc: 0.5000, loss: 0.0553 ||: 100%|██████████| 1040/1040 [00:24<00:00, 41.97it/s]\n",
      "accuracy: 0.9851, roc_auc: 0.5000, loss: 0.0642 ||: 100%|██████████| 223/223 [00:04<00:00, 54.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 3,\n",
       " 'peak_cpu_memory_MB': 3693.532,\n",
       " 'peak_gpu_0_memory_MB': 583,\n",
       " 'peak_gpu_1_memory_MB': 145,\n",
       " 'peak_gpu_2_memory_MB': 10,\n",
       " 'peak_gpu_3_memory_MB': 10633,\n",
       " 'training_duration': '0:03:09.386899',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 5,\n",
       " 'epoch': 5,\n",
       " 'training_accuracy': 0.9849996890548917,\n",
       " 'training_roc_auc': 0.5,\n",
       " 'training_loss': 0.05633270915758868,\n",
       " 'training_cpu_memory_MB': 3693.532,\n",
       " 'training_gpu_0_memory_MB': 583,\n",
       " 'training_gpu_1_memory_MB': 145,\n",
       " 'training_gpu_2_memory_MB': 10,\n",
       " 'training_gpu_3_memory_MB': 10633,\n",
       " 'validation_accuracy': 0.9849832746242724,\n",
       " 'validation_roc_auc': 0.5,\n",
       " 'validation_loss': 0.06385008288305169,\n",
       " 'best_validation_accuracy': 0.9847838804935276,\n",
       " 'best_validation_roc_auc': 0.5,\n",
       " 'best_validation_loss': 0.0629554661450231}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  4.94it/s]\u001b[A\n",
      "6it [00:00,  6.75it/s]\u001b[A\n",
      "12it [00:00,  9.13it/s]\u001b[A\n",
      "18it [00:00, 12.12it/s]\u001b[A\n",
      "24it [00:00, 15.75it/s]\u001b[A\n",
      "30it [00:00, 19.88it/s]\u001b[A\n",
      "36it [00:00, 24.34it/s]\u001b[A\n",
      "42it [00:01, 28.83it/s]\u001b[A\n",
      "47it [00:01, 32.93it/s]\u001b[A\n",
      "53it [00:01, 36.90it/s]\u001b[A\n",
      "59it [00:01, 40.34it/s]\u001b[A\n",
      "65it [00:01, 42.90it/s]\u001b[A\n",
      "71it [00:01, 45.04it/s]\u001b[A\n",
      "77it [00:01, 46.97it/s]\u001b[A\n",
      "83it [00:01, 48.49it/s]\u001b[A\n",
      "89it [00:01, 49.27it/s]\u001b[A\n",
      "95it [00:02, 49.93it/s]\u001b[A\n",
      "101it [00:02, 50.33it/s]\u001b[A\n",
      "107it [00:02, 50.67it/s]\u001b[A\n",
      "113it [00:02, 50.06it/s]\u001b[A\n",
      "119it [00:02, 50.71it/s]\u001b[A\n",
      "125it [00:02, 51.11it/s]\u001b[A\n",
      "131it [00:02, 51.27it/s]\u001b[A\n",
      "137it [00:02, 51.47it/s]\u001b[A\n",
      "143it [00:02, 51.97it/s]\u001b[A\n",
      "149it [00:03, 51.46it/s]\u001b[A\n",
      "155it [00:03, 52.07it/s]\u001b[A\n",
      "161it [00:03, 52.25it/s]\u001b[A\n",
      "167it [00:03, 51.17it/s]\u001b[A\n",
      "173it [00:03, 51.91it/s]\u001b[A\n",
      "179it [00:03, 52.49it/s]\u001b[A\n",
      "185it [00:03, 52.23it/s]\u001b[A\n",
      "191it [00:03, 51.89it/s]\u001b[A\n",
      "197it [00:04, 51.52it/s]\u001b[A\n",
      "203it [00:04, 50.81it/s]\u001b[A\n",
      "209it [00:04, 51.16it/s]\u001b[A\n",
      "215it [00:04, 50.93it/s]\u001b[A\n",
      "221it [00:04, 50.97it/s]\u001b[A\n",
      "223it [00:04, 49.18it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "dev_probs = []\n",
    "dev_labels = []\n",
    "\n",
    "for batch in tqdm(iterator(dev_dataset, num_epochs=1)):\n",
    "    \n",
    "    curr_labels = batch['label']\n",
    "    to_predict = batch['tokens']\n",
    "    to_predict['tokens'] = to_predict['tokens'].to(cuda_device)\n",
    "    \n",
    "    dev_probs.append(model(to_predict)['probs'].detach().cpu().numpy())\n",
    "    dev_labels.extend(list(curr_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_probs = np.vstack(dev_probs)\n",
    "dev_labels = np.array(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57011, 2), (57011,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_probs.shape, dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(probs, labels):\n",
    "\n",
    "    metrics = dict()\n",
    "    metrics['roc_auc'] = roc_auc_score(labels, probs[:, 1])\n",
    "    metrics['aver_pr'] = average_precision_score(labels, probs[:, 1])\n",
    "    metrics['f1'] = max(\n",
    "        [f1_score(y_true=labels, y_pred=(probs[:, 1] > threshold).astype(int))\n",
    "            for threshold in np.linspace(0.001, 0.99)]\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8378391125882765,\n",
       " 'aver_pr': 0.13977888279548203,\n",
       " 'f1': 0.21110555277638818}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resulted metrics\n",
    "\n",
    "calculate_metrics(dev_probs, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_examples = []\n",
    "original_examples = []\n",
    "\n",
    "with open('/mnt/chatbot_models2/fursov/texar/examples/text_style_transfer/samples_cropped/val.12') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i % 2 == 0:\n",
    "            original_examples.append(line.strip())\n",
    "        else:\n",
    "            adversarial_examples.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model=model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254243, 1254243)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adversarial_examples), len(original_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_examples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:25<00:00, 499.16it/s]\n"
     ]
    }
   ],
   "source": [
    "original_probs = []\n",
    "for example in tqdm(original_examples[:max_examples]):\n",
    "    original_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:02<00:00, 412.25it/s]\n"
     ]
    }
   ],
   "source": [
    "adversarial_probs = []\n",
    "for example in tqdm(adversarial_examples[:max_examples]):\n",
    "    if example:\n",
    "        adversarial_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_probs = np.array(original_probs)\n",
    "adversarial_probs = np.array(adversarial_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 2), (99677, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_probs.shape, adversarial_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean prob = 0.9868909656191617, median = 0.9957349002361298\n",
      "Original max prob = 1.0, min = 0.02725524827837944\n"
     ]
    }
   ],
   "source": [
    "print(f'Original mean prob = {original_probs[:, 0].mean()}, median = {np.median(original_probs[:, 0])}')\n",
    "print(f'Original max prob = {original_probs[:, 0].max()}, min = {original_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial mean prob = 0.19455415233026777, median = 4.211214036331512e-05\n",
      "Adversarial max prob = 1.0, min = 1.528894633624645e-23\n"
     ]
    }
   ],
   "source": [
    "print(f'Adversarial mean prob = {adversarial_probs[:, 0].mean()}, median = {np.median(adversarial_probs[:, 0])}')\n",
    "print(f'Adversarial max prob = {adversarial_probs[:, 0].max()}, min = {adversarial_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

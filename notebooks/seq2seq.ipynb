{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models.encoder_decoders.composed_seq2seq import ComposedSeq2Seq\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.attention.additive_attention import AdditiveAttention\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "\n",
    "\n",
    "from typing import Dict\n",
    "import csv\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, Field, MetadataField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.token import Token\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.tokenizers import Tokenizer\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.attention.additive_attention import AdditiveAttention\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.common.util import END_SYMBOL, START_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LovelyModel(SimpleSeq2Seq):\n",
    "\n",
    "    def _prepare_output_projections(self,\n",
    "                                    last_predictions: torch.Tensor,\n",
    "                                    state: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        encoder_outputs = state[\"encoder_outputs\"]\n",
    "        source_mask = state[\"source_mask\"]\n",
    "        decoder_hidden = state[\"decoder_hidden\"]\n",
    "        decoder_context = state[\"decoder_context\"]\n",
    "        embedded_input = self._source_embedder._token_embedders['tokens'](last_predictions)\n",
    "        if self._attention:\n",
    "            attended_input = self._prepare_attended_input(decoder_hidden, encoder_outputs, source_mask)\n",
    "            decoder_input = torch.cat((attended_input, embedded_input), -1)\n",
    "        else:\n",
    "            decoder_input = embedded_input\n",
    "        decoder_hidden, decoder_context = self._decoder_cell(\n",
    "                decoder_input,\n",
    "                (decoder_hidden, decoder_context))\n",
    "\n",
    "        state[\"decoder_hidden\"] = decoder_hidden\n",
    "        state[\"decoder_context\"] = decoder_context\n",
    "\n",
    "        output_projections = self._output_projection_layer(decoder_hidden)\n",
    "        return output_projections, state\n",
    "\n",
    "    def forward(self,  # type: ignore\n",
    "                source_tokens: Dict[str, torch.LongTensor],\n",
    "                target_tokens: Dict[str, torch.LongTensor] = None, **kwargs):\n",
    "        del kwargs\n",
    "        return super().forward(source_tokens, target_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model(vocab: Vocabulary) -> SimpleSeq2Seq:\n",
    "    emb_dim = 64\n",
    "    hidden_dim = 32\n",
    "    token_embedding = Embedding(\n",
    "        num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "        embedding_dim=emb_dim\n",
    "    )\n",
    "\n",
    "    word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "    lstm = PytorchSeq2SeqWrapper(nn.LSTM(emb_dim, hidden_dim, batch_first=True))\n",
    "\n",
    "    model = LovelyModel(\n",
    "        vocab=vocab,\n",
    "        source_embedder=word_embeddings,\n",
    "        encoder=lstm,\n",
    "        max_decoding_steps=20,\n",
    "        attention=AdditiveAttention(vector_dim=hidden_dim, matrix_dim=hidden_dim)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReader(DatasetReader):\n",
    "\n",
    "    def _read(self, file_path):\n",
    "        with open(cached_path(file_path), \"r\") as file:\n",
    "            for line in file:\n",
    "                yield self.text_to_instance(line.strip())\n",
    "\n",
    "    def text_to_instance(\n",
    "        self,\n",
    "        text: str\n",
    "    ) -> Instance:\n",
    "        fields: Dict[str, Field] = {}\n",
    "        tokenized = [START_SYMBOL] + text.split() + [END_SYMBOL]\n",
    "        fields[\"source_tokens\"] = TextField([Token(word) for word in tokenized], {\"tokens\": SingleIdTokenIndexer()})\n",
    "        fields[\"target_tokens\"] = fields[\"source_tokens\"]\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../texar/examples/text_style_transfer/data/insurance_cropped/insurance.train.text'\n",
    "test_path = '../../texar/examples/text_style_transfer/data/insurance_cropped/insurance.test.text'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MyReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266051it [00:14, 18056.54it/s]\n",
      "57012it [00:03, 15913.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(train_path)\n",
    "test_dataset = reader.read(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = Vocabulary.from_instances(train_dataset + test_dataset)\n",
    "vocab = Vocabulary.from_files('vocab_seq2seq/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=256)\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_baseline_model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LovelyModel(\n",
       "  (_source_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_encoder): PytorchSeq2SeqWrapper(\n",
       "    (_module): LSTM(64, 32, batch_first=True)\n",
       "  )\n",
       "  (_attention): AdditiveAttention()\n",
       "  (_target_embedder): Embedding()\n",
       "  (_decoder_cell): LSTMCell(96, 32)\n",
       "  (_output_projection_layer): Linear(in_features=32, out_features=2149, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=test_dataset,\n",
    "    patience=2,\n",
    "    num_epochs=10,\n",
    "    cuda_device=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"model_seq2seq.th\", 'wb') as f:\n",
    "#     torch.save(model.state_dict(), f)\n",
    "\n",
    "# vocab.save_to_files(\"vocab_seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from allennlp.predictors import Seq2SeqPredictor, TextClassifierPredictor\n",
    "from adat.utils import load_weights\n",
    "from adat.models import get_basic_classification_model, get_basic_seq2seq_model\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from adat.dataset import InsuranceReader, Seq2SeqReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_reader = Seq2SeqReader()\n",
    "seq2seq_vocab = Vocabulary.from_files('vocab_seq2seq')\n",
    "seq2seq_model = get_basic_seq2seq_model(seq2seq_vocab)\n",
    "load_weights(seq2seq_model, 'model_seq2seq.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_reader = InsuranceReader()\n",
    "class_vocab = Vocabulary.from_files('vocab_classification')\n",
    "class_model = get_basic_classification_model(class_vocab)\n",
    "load_weights(class_model, 'model_classification.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_predictor = Seq2SeqPredictor(seq2seq_model, seq2seq_reader)\n",
    "class_predictor = TextClassifierPredictor(class_model, class_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '{test_path}' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! head {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = \"\"\"a_1139\n",
    "a_1943 a_1978 a_1 a_1149 a_1138 a_1286 a_1158 a_2001 a_1938\n",
    "a_1 a_1667 a_340 a_1978 a_1669 a_2001\n",
    "a_876 a_1213 a_1020 a_1129 a_1120 a_1121 a_1215\n",
    "a_1119 a_1137 a_1139\n",
    "a_737 a_734 a_1191 a_1111 a_644 a_1257 a_1128 a_19 a_1978 a_733 a_20 a_1 a_39 a_35 a_755\n",
    "a_1656 a_2014 a_1257 a_2013 a_2013 a_340 a_549 a_340 a_1191 a_340 a_340 a_362 a_1 a_2014 a_1111\n",
    "a_1\n",
    "a_1257 a_1191 a_549 a_362 a_1191 a_1927 a_1138 a_1111 a_1929 a_1656 a_1920 a_1 a_2001 a_1257\n",
    "a_1978 a_645\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(sequence: str, seq_to_seq_predictor: Seq2SeqPredictor = seq2seq_predictor) -> str:\n",
    "    return ' '.join(seq_to_seq_predictor.predict(sequence)['predicted_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = a_1139\n",
      "Output = a_1139\n",
      "\n",
      "Input = a_1943 a_1978 a_1 a_1149 a_1138 a_1286 a_1158 a_2001 a_1938\n",
      "Output = a_1943 a_1978 a_1 a_1149 a_1138 a_1286 a_1158 a_2001 a_1938\n",
      "\n",
      "Input = a_1 a_1667 a_340 a_1978 a_1669 a_2001\n",
      "Output = a_1 a_1667 a_340 a_1978 a_1669 a_2001\n",
      "\n",
      "Input = a_876 a_1213 a_1020 a_1129 a_1120 a_1121 a_1215\n",
      "Output = a_876 a_1213 a_1020 a_1129 a_1120 a_1121 a_1215\n",
      "\n",
      "Input = a_1119 a_1137 a_1139\n",
      "Output = a_1119 a_1137 a_1139\n",
      "\n",
      "Input = a_737 a_734 a_1191 a_1111 a_644 a_1257 a_1128 a_19 a_1978 a_733 a_20 a_1 a_39 a_35 a_755\n",
      "Output = a_737 a_734 a_1191 a_1111 a_644 a_1257 a_1128 a_1128 a_1111 a_733 a_20 a_1 a_39 a_35 a_35 a_810\n",
      "\n",
      "Input = a_1656 a_2014 a_1257 a_2013 a_2013 a_340 a_549 a_340 a_1191 a_340 a_340 a_362 a_1 a_2014 a_1111\n",
      "Output = a_1656 a_2014 a_1257 a_2013 a_2013 a_340 a_549 a_340 a_1191 a_340 a_340 a_362 a_1 a_2014 a_1111 a_1111\n",
      "\n",
      "Input = a_1\n",
      "Output = a_1\n",
      "\n",
      "Input = a_1257 a_1191 a_549 a_362 a_1191 a_1927 a_1138 a_1111 a_1929 a_1656 a_1920 a_1 a_2001 a_1257\n",
      "Output = a_1257 a_1191 a_549 a_362 a_1191 a_1927 a_1138 a_1138 a_1891 a_1656 a_1920 a_1 a_2001 a_1257\n",
      "\n",
      "Input = a_1978 a_645\n",
      "Output = a_1978 a_645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "    predicted_seq = predict_sequence(seq)\n",
    "    print(f'Input = {seq}\\nOutput = {predicted_seq}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_iterator = BasicIterator()\n",
    "seq2seq_iterator.index_with(seq2seq_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_iterator = BasicIterator()\n",
    "class_iterator.index_with(class_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.data.instance.Instance at 0x7fc94efab438>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_reader.text_to_instance('a_1978 a_645')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

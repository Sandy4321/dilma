{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy, Auc\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import TextClassifierPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from adat.models import get_basic_classification_model\n",
    "from adat.dataset import InsuranceReader, CsvReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2496it [00:00, 13319.30it/s]\u001b[A\n",
      "5247it [00:00, 15757.21it/s]\u001b[A\n",
      "6507it [00:00, 11266.72it/s]\u001b[A\n",
      "9474it [00:00, 13842.43it/s]\u001b[A\n",
      "11048it [00:00, 11439.18it/s]\u001b[A\n",
      "12875it [00:00, 12883.18it/s]\u001b[A\n",
      "14647it [00:00, 14031.09it/s]\u001b[A\n",
      "16222it [00:01, 10095.51it/s]\u001b[A\n",
      "18711it [00:01, 12285.97it/s]\u001b[A\n",
      "21288it [00:01, 14572.32it/s]\u001b[A\n",
      "23213it [00:01, 9874.73it/s] \u001b[A\n",
      "25302it [00:01, 11730.01it/s]\u001b[A\n",
      "26991it [00:01, 12822.21it/s]\u001b[A\n",
      "28993it [00:02, 9873.14it/s] \u001b[A\n",
      "31810it [00:02, 12262.36it/s]\u001b[A\n",
      "34692it [00:02, 14815.28it/s]\u001b[A\n",
      "37400it [00:02, 17143.81it/s]\u001b[A\n",
      "39700it [00:02, 11070.45it/s]\u001b[A\n",
      "42564it [00:03, 13567.09it/s]\u001b[A\n",
      "45591it [00:03, 16258.19it/s]\u001b[A\n",
      "48498it [00:03, 18734.72it/s]\u001b[A\n",
      "51041it [00:03, 11531.82it/s]\u001b[A\n",
      "53628it [00:03, 13824.80it/s]\u001b[A\n",
      "56647it [00:03, 16509.24it/s]\u001b[A\n",
      "59551it [00:03, 18963.09it/s]\u001b[A\n",
      "62109it [00:04, 20511.77it/s]\u001b[A\n",
      "64660it [00:04, 21661.99it/s]\u001b[A\n",
      "67193it [00:04, 11485.81it/s]\u001b[A\n",
      "69975it [00:04, 13941.23it/s]\u001b[A\n",
      "72909it [00:04, 16546.49it/s]\u001b[A\n",
      "75956it [00:04, 19174.99it/s]\u001b[A\n",
      "78964it [00:05, 21514.91it/s]\u001b[A\n",
      "82002it [00:05, 23577.53it/s]\u001b[A\n",
      "84821it [00:05, 11413.01it/s]\u001b[A\n",
      "87553it [00:05, 13828.46it/s]\u001b[A\n",
      "90572it [00:05, 16513.27it/s]\u001b[A\n",
      "93095it [00:05, 18252.57it/s]\u001b[A\n",
      "95587it [00:06, 19449.89it/s]\u001b[A\n",
      "98626it [00:06, 21804.43it/s]\u001b[A\n",
      "101511it [00:06, 23527.36it/s]\u001b[A\n",
      "104567it [00:06, 25271.40it/s]\u001b[A\n",
      "107371it [00:07, 9694.02it/s] \u001b[A\n",
      "110299it [00:07, 12127.73it/s]\u001b[A\n",
      "113230it [00:07, 14715.12it/s]\u001b[A\n",
      "116238it [00:07, 17378.00it/s]\u001b[A\n",
      "119186it [00:07, 19818.40it/s]\u001b[A\n",
      "122151it [00:07, 22005.45it/s]\u001b[A\n",
      "124964it [00:07, 23292.08it/s]\u001b[A\n",
      "127998it [00:07, 25035.15it/s]\u001b[A\n",
      "131080it [00:07, 26528.17it/s]\u001b[A\n",
      "134142it [00:08, 27635.51it/s]\u001b[A\n",
      "137107it [00:08, 9199.43it/s] \u001b[A\n",
      "139671it [00:08, 11389.39it/s]\u001b[A\n",
      "142668it [00:09, 13991.33it/s]\u001b[A\n",
      "145707it [00:09, 16693.75it/s]\u001b[A\n",
      "148623it [00:09, 19147.14it/s]\u001b[A\n",
      "151513it [00:09, 21302.50it/s]\u001b[A\n",
      "154456it [00:09, 23225.42it/s]\u001b[A\n",
      "157361it [00:09, 24711.09it/s]\u001b[A\n",
      "160215it [00:09, 25202.28it/s]\u001b[A\n",
      "163006it [00:09, 24814.43it/s]\u001b[A\n",
      "165679it [00:09, 24924.55it/s]\u001b[A\n",
      "168646it [00:09, 26180.67it/s]\u001b[A\n",
      "171668it [00:10, 27272.70it/s]\u001b[A\n",
      "174485it [00:10, 8276.26it/s] \u001b[A\n",
      "176999it [00:11, 10355.23it/s]\u001b[A\n",
      "179680it [00:11, 12691.67it/s]\u001b[A\n",
      "182275it [00:11, 14988.96it/s]\u001b[A\n",
      "185130it [00:11, 17479.02it/s]\u001b[A\n",
      "188114it [00:11, 19958.94it/s]\u001b[A\n",
      "191209it [00:11, 22337.85it/s]\u001b[A\n",
      "194187it [00:11, 24146.48it/s]\u001b[A\n",
      "197043it [00:11, 25118.84it/s]\u001b[A\n",
      "199874it [00:11, 25903.63it/s]\u001b[A\n",
      "202694it [00:11, 26459.79it/s]\u001b[A\n",
      "205707it [00:12, 27462.20it/s]\u001b[A\n",
      "208640it [00:12, 27996.68it/s]\u001b[A\n",
      "211530it [00:12, 28074.07it/s]\u001b[A\n",
      "214401it [00:12, 27398.71it/s]\u001b[A\n",
      "217189it [00:13, 6697.73it/s] \u001b[A\n",
      "220066it [00:13, 8700.09it/s]\u001b[A\n",
      "222490it [00:13, 10771.62it/s]\u001b[A\n",
      "225143it [00:13, 13106.86it/s]\u001b[A\n",
      "227662it [00:13, 15309.96it/s]\u001b[A\n",
      "230442it [00:14, 17694.65it/s]\u001b[A\n",
      "233395it [00:14, 20112.92it/s]\u001b[A\n",
      "236288it [00:14, 22135.71it/s]\u001b[A\n",
      "239147it [00:14, 23742.01it/s]\u001b[A\n",
      "242063it [00:14, 25142.69it/s]\u001b[A\n",
      "245038it [00:14, 26367.10it/s]\u001b[A\n",
      "248104it [00:14, 27522.72it/s]\u001b[A\n",
      "251029it [00:14, 27451.24it/s]\u001b[A\n",
      "254045it [00:14, 28211.19it/s]\u001b[A\n",
      "257000it [00:14, 28598.44it/s]\u001b[A\n",
      "259924it [00:15, 28510.75it/s]\u001b[A\n",
      "262820it [00:15, 28067.84it/s]\u001b[A\n",
      "265660it [00:15, 27107.63it/s]\u001b[A\n",
      "270599it [00:15, 17515.58it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "# reader = InsuranceReader()\n",
    "reader = CsvReader()\n",
    "\n",
    "train_dataset = reader.read('../../data/kaggle_transactions_data/train.csv')\n",
    "# test_dataset = reader.read('../data/kaggle_transactions_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306998/306998 [00:04<00:00, 72581.22it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=1024)\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 18 21:14:06 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   28C    P8     9W / 280W |  10277MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   29C    P8     8W / 280W |  10806MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "|  0%   46C    P0    71W / 280W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "|  0%   25C    P8     9W / 280W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_basic_classification_model(vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicClassifier(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2seq_encoder): PytorchSeq2SeqWrapper(\n",
       "    (_module): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (_seq2vec_encoder): BoWMaxAndMeanEncoder(\n",
       "    (maxer): BoWMaxEncoder()\n",
       "    (meaner): BagOfEmbeddingsEncoder()\n",
       "  )\n",
       "  (_classification_layer): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "patience = 2\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=test_dataset,\n",
    "    serialization_dir='experiments/kaggle_exp_4',\n",
    "    patience=patience,\n",
    "    num_epochs=num_epochs,\n",
    "    cuda_device=cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6737, loss: 0.6001 ||: 100%|██████████| 285/285 [01:38<00:00,  2.88it/s]\n",
      "accuracy: 0.6880, loss: 0.5863 ||: 100%|██████████| 15/15 [00:02<00:00,  5.11it/s]\n",
      "accuracy: 0.6928, loss: 0.5781 ||: 100%|██████████| 285/285 [01:30<00:00,  3.15it/s]\n",
      "accuracy: 0.6912, loss: 0.5833 ||: 100%|██████████| 15/15 [00:02<00:00,  5.69it/s]\n",
      "accuracy: 0.6973, loss: 0.5699 ||: 100%|██████████| 285/285 [01:31<00:00,  3.11it/s]\n",
      "accuracy: 0.6913, loss: 0.5814 ||: 100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n",
      "accuracy: 0.7020, loss: 0.5629 ||: 100%|██████████| 285/285 [01:33<00:00,  3.06it/s]\n",
      "accuracy: 0.6903, loss: 0.5840 ||: 100%|██████████| 15/15 [00:02<00:00,  5.96it/s]\n",
      "accuracy: 0.7057, loss: 0.5557 ||: 100%|██████████| 285/285 [01:34<00:00,  3.01it/s]\n",
      "accuracy: 0.6920, loss: 0.5839 ||: 100%|██████████| 15/15 [00:02<00:00,  5.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 2,\n",
       " 'peak_cpu_memory_MB': 4200.432,\n",
       " 'peak_gpu_0_memory_MB': 10277,\n",
       " 'peak_gpu_1_memory_MB': 10806,\n",
       " 'peak_gpu_2_memory_MB': 9547,\n",
       " 'peak_gpu_3_memory_MB': 10,\n",
       " 'training_duration': '0:06:28.322201',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 3,\n",
       " 'epoch': 3,\n",
       " 'training_accuracy': 0.7019660686855387,\n",
       " 'training_loss': 0.5629137595494588,\n",
       " 'training_cpu_memory_MB': 4200.432,\n",
       " 'training_gpu_0_memory_MB': 10277,\n",
       " 'training_gpu_1_memory_MB': 10806,\n",
       " 'training_gpu_2_memory_MB': 9547,\n",
       " 'training_gpu_3_memory_MB': 10,\n",
       " 'validation_accuracy': 0.6902931596091205,\n",
       " 'validation_loss': 0.5840107679367066,\n",
       " 'best_validation_accuracy': 0.6913355048859935,\n",
       " 'best_validation_loss': 0.58143124183019}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6263, loss: 0.6473 ||: 100%|██████████| 72/72 [01:54<00:00,  1.59s/it]\n",
      "accuracy: 0.6818, loss: 0.6039 ||: 100%|██████████| 4/4 [00:04<00:00,  1.00s/it]\n",
      "accuracy: 0.6820, loss: 0.5961 ||: 100%|██████████| 72/72 [01:36<00:00,  1.35s/it]\n",
      "accuracy: 0.6798, loss: 0.5999 ||: 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]\n",
      "accuracy: 0.6847, loss: 0.5898 ||: 100%|██████████| 72/72 [01:47<00:00,  1.49s/it]\n",
      "accuracy: 0.6866, loss: 0.5919 ||: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]\n",
      "accuracy: 0.6872, loss: 0.5863 ||: 100%|██████████| 72/72 [01:42<00:00,  1.43s/it]\n",
      "accuracy: 0.6852, loss: 0.5920 ||: 100%|██████████| 4/4 [00:03<00:00,  1.09it/s]\n",
      "accuracy: 0.6928, loss: 0.5791 ||:  29%|██▉       | 21/72 [00:26<01:12,  1.43s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;31m# get peak of memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    311\u001b[0m                                          total=num_training_batches)\n\u001b[1;32m    312\u001b[0m         \u001b[0mcumulative_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mbatches_this_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mspecified\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0minstances\u001b[0m \u001b[0mleft\u001b[0m \u001b[0mover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m def pad_sequence_to_length(sequence: List,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/iterators/data_iterator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, instances, num_epochs, shuffle)\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch padding lengths: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch size: %d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                     \u001b[0mtensor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0madd_to_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/dataset.py\u001b[0m in \u001b[0;36mas_tensor_dict\u001b[0;34m(self, padding_lengths, verbose)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now actually padding instances to length: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mfield_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/instance.py\u001b[0m in \u001b[0;36mas_tensor_dict\u001b[0;34m(self, padding_lengths)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/fields/text_field.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(self, padding_lengths)\u001b[0m\n\u001b[1;32m    148\u001b[0m             indexer_tensors = indexer.as_padded_tensor(indices_to_pad,\n\u001b[1;32m    149\u001b[0m                                                        \u001b[0mdesired_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                                                        padding_lengths)\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;31m# We use the key of the indexer to recognise what the tensor corresponds to within the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# field (i.e. the result of word indexing, or the result of character indexing, for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/single_id_token_indexer.py\u001b[0m in \u001b[0;36mas_padded_tensor\u001b[0;34m(self, tokens, desired_num_tokens, padding_lengths)\u001b[0m\n\u001b[1;32m     84\u001b[0m                          padding_lengths: Dict[str, int]) -> Dict[str, torch.Tensor]:  # pylint: disable=unused-argument\n\u001b[1;32m     85\u001b[0m         return {key: torch.LongTensor(pad_sequence_to_length(val, desired_num_tokens[key]))\n\u001b[0;32m---> 86\u001b[0;31m                 for key, val in tokens.items()}\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/single_id_token_indexer.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     84\u001b[0m                          padding_lengths: Dict[str, int]) -> Dict[str, torch.Tensor]:  # pylint: disable=unused-argument\n\u001b[1;32m     85\u001b[0m         return {key: torch.LongTensor(pad_sequence_to_length(val, desired_num_tokens[key]))\n\u001b[0;32m---> 86\u001b[0;31m                 for key, val in tokens.items()}\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\u001b[0m in \u001b[0;36mpad_sequence_to_length\u001b[0;34m(sequence, desired_length, default_value, padding_on_right)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_on_right\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mpadded_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mpadded_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"model_classification2.th\", 'wb') as f:\n",
    "#     torch.save(model.state_dict(), f)\n",
    "\n",
    "# vocab.save_to_files(\"vocab_classification2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  4.94it/s]\u001b[A\n",
      "6it [00:00,  6.75it/s]\u001b[A\n",
      "12it [00:00,  9.13it/s]\u001b[A\n",
      "18it [00:00, 12.12it/s]\u001b[A\n",
      "24it [00:00, 15.75it/s]\u001b[A\n",
      "30it [00:00, 19.88it/s]\u001b[A\n",
      "36it [00:00, 24.34it/s]\u001b[A\n",
      "42it [00:01, 28.83it/s]\u001b[A\n",
      "47it [00:01, 32.93it/s]\u001b[A\n",
      "53it [00:01, 36.90it/s]\u001b[A\n",
      "59it [00:01, 40.34it/s]\u001b[A\n",
      "65it [00:01, 42.90it/s]\u001b[A\n",
      "71it [00:01, 45.04it/s]\u001b[A\n",
      "77it [00:01, 46.97it/s]\u001b[A\n",
      "83it [00:01, 48.49it/s]\u001b[A\n",
      "89it [00:01, 49.27it/s]\u001b[A\n",
      "95it [00:02, 49.93it/s]\u001b[A\n",
      "101it [00:02, 50.33it/s]\u001b[A\n",
      "107it [00:02, 50.67it/s]\u001b[A\n",
      "113it [00:02, 50.06it/s]\u001b[A\n",
      "119it [00:02, 50.71it/s]\u001b[A\n",
      "125it [00:02, 51.11it/s]\u001b[A\n",
      "131it [00:02, 51.27it/s]\u001b[A\n",
      "137it [00:02, 51.47it/s]\u001b[A\n",
      "143it [00:02, 51.97it/s]\u001b[A\n",
      "149it [00:03, 51.46it/s]\u001b[A\n",
      "155it [00:03, 52.07it/s]\u001b[A\n",
      "161it [00:03, 52.25it/s]\u001b[A\n",
      "167it [00:03, 51.17it/s]\u001b[A\n",
      "173it [00:03, 51.91it/s]\u001b[A\n",
      "179it [00:03, 52.49it/s]\u001b[A\n",
      "185it [00:03, 52.23it/s]\u001b[A\n",
      "191it [00:03, 51.89it/s]\u001b[A\n",
      "197it [00:04, 51.52it/s]\u001b[A\n",
      "203it [00:04, 50.81it/s]\u001b[A\n",
      "209it [00:04, 51.16it/s]\u001b[A\n",
      "215it [00:04, 50.93it/s]\u001b[A\n",
      "221it [00:04, 50.97it/s]\u001b[A\n",
      "223it [00:04, 49.18it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "dev_probs = []\n",
    "dev_labels = []\n",
    "\n",
    "for batch in tqdm(iterator(dev_dataset, num_epochs=1)):\n",
    "    \n",
    "    curr_labels = batch['label']\n",
    "    to_predict = batch['tokens']\n",
    "    to_predict['tokens'] = to_predict['tokens'].to(cuda_device)\n",
    "    \n",
    "    dev_probs.append(model(to_predict)['probs'].detach().cpu().numpy())\n",
    "    dev_labels.extend(list(curr_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_probs = np.vstack(dev_probs)\n",
    "dev_labels = np.array(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57011, 2), (57011,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_probs.shape, dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(probs, labels):\n",
    "\n",
    "    metrics = dict()\n",
    "    metrics['roc_auc'] = roc_auc_score(labels, probs[:, 1])\n",
    "    metrics['aver_pr'] = average_precision_score(labels, probs[:, 1])\n",
    "    metrics['f1'] = max(\n",
    "        [f1_score(y_true=labels, y_pred=(probs[:, 1] > threshold).astype(int))\n",
    "            for threshold in np.linspace(0.001, 0.99)]\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8378391125882765,\n",
       " 'aver_pr': 0.13977888279548203,\n",
       " 'f1': 0.21110555277638818}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resulted metrics\n",
    "\n",
    "calculate_metrics(dev_probs, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_examples = []\n",
    "original_examples = []\n",
    "\n",
    "with open('/mnt/chatbot_models2/fursov/texar/examples/text_style_transfer/samples_cropped/val.12') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i % 2 == 0:\n",
    "            original_examples.append(line.strip())\n",
    "        else:\n",
    "            adversarial_examples.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model=model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254243, 1254243)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adversarial_examples), len(original_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_examples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:25<00:00, 499.16it/s]\n"
     ]
    }
   ],
   "source": [
    "original_probs = []\n",
    "for example in tqdm(original_examples[:max_examples]):\n",
    "    original_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:02<00:00, 412.25it/s]\n"
     ]
    }
   ],
   "source": [
    "adversarial_probs = []\n",
    "for example in tqdm(adversarial_examples[:max_examples]):\n",
    "    if example:\n",
    "        adversarial_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_probs = np.array(original_probs)\n",
    "adversarial_probs = np.array(adversarial_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 2), (99677, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_probs.shape, adversarial_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean prob = 0.9868909656191617, median = 0.9957349002361298\n",
      "Original max prob = 1.0, min = 0.02725524827837944\n"
     ]
    }
   ],
   "source": [
    "print(f'Original mean prob = {original_probs[:, 0].mean()}, median = {np.median(original_probs[:, 0])}')\n",
    "print(f'Original max prob = {original_probs[:, 0].max()}, min = {original_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial mean prob = 0.19455415233026777, median = 4.211214036331512e-05\n",
      "Adversarial max prob = 1.0, min = 1.528894633624645e-23\n"
     ]
    }
   ],
   "source": [
    "print(f'Adversarial mean prob = {adversarial_probs[:, 0].mean()}, median = {np.median(adversarial_probs[:, 0])}')\n",
    "print(f'Adversarial max prob = {adversarial_probs[:, 0].max()}, min = {adversarial_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

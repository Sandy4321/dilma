{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy, Auc\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import TextClassifierPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from adat.models import get_basic_classification_model\n",
    "from adat.dataset import InsuranceReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.zip\t\t     test.text\t       transactions_test.csv\r\n",
      "small_group_description.csv  train.labels      transactions_train.csv\r\n",
      "test.csv\t\t     train_target.csv\r\n",
      "test.labels\t\t     train.text\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220739it [00:09, 24075.95it/s]\n",
      "47224it [00:01, 24121.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "reader = InsuranceReader()\n",
    "\n",
    "train_dataset = reader.read(data_path + 'train')\n",
    "test_dataset = reader.read(data_path + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267963/267963 [00:01<00:00, 137751.69it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BasicIterator(batch_size=4096)\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_basic_classification_model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicClassifier(\n",
       "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (_seq2seq_encoder): PytorchSeq2SeqWrapper(\n",
       "    (_module): LSTM(32, 16, batch_first=True)\n",
       "  )\n",
       "  (_seq2vec_encoder): BagOfEmbeddingsEncoder()\n",
       "  (_classification_layer): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=test_dataset,\n",
    "    patience=2,\n",
    "    num_epochs=30,\n",
    "    cuda_device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9772, loss: 0.2432 ||: 100%|██████████| 54/54 [00:12<00:00,  5.17it/s]\n",
      "accuracy: 0.9893, loss: 0.1234 ||: 100%|██████████| 12/12 [00:02<00:00,  5.87it/s]\n",
      "accuracy: 0.9891, loss: 0.0855 ||: 100%|██████████| 54/54 [00:11<00:00,  5.23it/s]\n",
      "accuracy: 0.9888, loss: 0.0688 ||: 100%|██████████| 12/12 [00:03<00:00,  2.51it/s]\n",
      "accuracy: 0.9890, loss: 0.0592 ||: 100%|██████████| 54/54 [00:10<00:00,  5.27it/s]\n",
      "accuracy: 0.9891, loss: 0.0575 ||: 100%|██████████| 12/12 [00:02<00:00,  5.63it/s]\n",
      "accuracy: 0.9892, loss: 0.0522 ||: 100%|██████████| 54/54 [00:12<00:00,  5.39it/s]\n",
      "accuracy: 0.9891, loss: 0.0539 ||: 100%|██████████| 12/12 [00:02<00:00,  6.31it/s]\n",
      "accuracy: 0.9893, loss: 0.0488 ||: 100%|██████████| 54/54 [00:10<00:00,  4.97it/s]\n",
      "accuracy: 0.9891, loss: 0.0527 ||: 100%|██████████| 12/12 [00:02<00:00,  5.62it/s]\n",
      "accuracy: 0.9894, loss: 0.0469 ||: 100%|██████████| 54/54 [00:11<00:00,  5.41it/s]\n",
      "accuracy: 0.9891, loss: 0.0520 ||: 100%|██████████| 12/12 [00:02<00:00,  5.67it/s]\n",
      "accuracy: 0.9895, loss: 0.0453 ||: 100%|██████████| 54/54 [00:11<00:00,  4.91it/s]\n",
      "accuracy: 0.9888, loss: 0.0513 ||: 100%|██████████| 12/12 [00:03<00:00,  5.19it/s]\n",
      "accuracy: 0.9895, loss: 0.0441 ||: 100%|██████████| 54/54 [00:10<00:00,  5.34it/s]\n",
      "accuracy: 0.9884, loss: 0.0511 ||: 100%|██████████| 12/12 [00:02<00:00,  5.85it/s]\n",
      "accuracy: 0.9896, loss: 0.0432 ||: 100%|██████████| 54/54 [00:12<00:00,  5.11it/s]\n",
      "accuracy: 0.9889, loss: 0.0513 ||: 100%|██████████| 12/12 [00:02<00:00,  6.23it/s]\n",
      "accuracy: 0.9896, loss: 0.0425 ||: 100%|██████████| 54/54 [00:10<00:00,  5.44it/s]\n",
      "accuracy: 0.9883, loss: 0.0512 ||: 100%|██████████| 12/12 [00:02<00:00,  6.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 7,\n",
       " 'peak_cpu_memory_MB': 3255.652,\n",
       " 'peak_gpu_0_memory_MB': 2363,\n",
       " 'peak_gpu_1_memory_MB': 573,\n",
       " 'peak_gpu_2_memory_MB': 10,\n",
       " 'peak_gpu_3_memory_MB': 577,\n",
       " 'training_duration': '0:02:06.671360',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 8,\n",
       " 'epoch': 8,\n",
       " 'training_accuracy': 0.9895623337969276,\n",
       " 'training_loss': 0.043179076406414864,\n",
       " 'training_cpu_memory_MB': 3255.652,\n",
       " 'training_gpu_0_memory_MB': 2363,\n",
       " 'training_gpu_1_memory_MB': 573,\n",
       " 'training_gpu_2_memory_MB': 10,\n",
       " 'training_gpu_3_memory_MB': 577,\n",
       " 'validation_accuracy': 0.9888827714721328,\n",
       " 'validation_loss': 0.05132229377826055,\n",
       " 'best_validation_accuracy': 0.9883957309842453,\n",
       " 'best_validation_loss': 0.05109726885954539}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"model_classification2.th\", 'wb') as f:\n",
    "#     torch.save(model.state_dict(), f)\n",
    "\n",
    "# vocab.save_to_files(\"vocab_classification2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  4.94it/s]\u001b[A\n",
      "6it [00:00,  6.75it/s]\u001b[A\n",
      "12it [00:00,  9.13it/s]\u001b[A\n",
      "18it [00:00, 12.12it/s]\u001b[A\n",
      "24it [00:00, 15.75it/s]\u001b[A\n",
      "30it [00:00, 19.88it/s]\u001b[A\n",
      "36it [00:00, 24.34it/s]\u001b[A\n",
      "42it [00:01, 28.83it/s]\u001b[A\n",
      "47it [00:01, 32.93it/s]\u001b[A\n",
      "53it [00:01, 36.90it/s]\u001b[A\n",
      "59it [00:01, 40.34it/s]\u001b[A\n",
      "65it [00:01, 42.90it/s]\u001b[A\n",
      "71it [00:01, 45.04it/s]\u001b[A\n",
      "77it [00:01, 46.97it/s]\u001b[A\n",
      "83it [00:01, 48.49it/s]\u001b[A\n",
      "89it [00:01, 49.27it/s]\u001b[A\n",
      "95it [00:02, 49.93it/s]\u001b[A\n",
      "101it [00:02, 50.33it/s]\u001b[A\n",
      "107it [00:02, 50.67it/s]\u001b[A\n",
      "113it [00:02, 50.06it/s]\u001b[A\n",
      "119it [00:02, 50.71it/s]\u001b[A\n",
      "125it [00:02, 51.11it/s]\u001b[A\n",
      "131it [00:02, 51.27it/s]\u001b[A\n",
      "137it [00:02, 51.47it/s]\u001b[A\n",
      "143it [00:02, 51.97it/s]\u001b[A\n",
      "149it [00:03, 51.46it/s]\u001b[A\n",
      "155it [00:03, 52.07it/s]\u001b[A\n",
      "161it [00:03, 52.25it/s]\u001b[A\n",
      "167it [00:03, 51.17it/s]\u001b[A\n",
      "173it [00:03, 51.91it/s]\u001b[A\n",
      "179it [00:03, 52.49it/s]\u001b[A\n",
      "185it [00:03, 52.23it/s]\u001b[A\n",
      "191it [00:03, 51.89it/s]\u001b[A\n",
      "197it [00:04, 51.52it/s]\u001b[A\n",
      "203it [00:04, 50.81it/s]\u001b[A\n",
      "209it [00:04, 51.16it/s]\u001b[A\n",
      "215it [00:04, 50.93it/s]\u001b[A\n",
      "221it [00:04, 50.97it/s]\u001b[A\n",
      "223it [00:04, 49.18it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "dev_probs = []\n",
    "dev_labels = []\n",
    "\n",
    "for batch in tqdm(iterator(dev_dataset, num_epochs=1)):\n",
    "    \n",
    "    curr_labels = batch['label']\n",
    "    to_predict = batch['tokens']\n",
    "    to_predict['tokens'] = to_predict['tokens'].to(cuda_device)\n",
    "    \n",
    "    dev_probs.append(model(to_predict)['probs'].detach().cpu().numpy())\n",
    "    dev_labels.extend(list(curr_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_probs = np.vstack(dev_probs)\n",
    "dev_labels = np.array(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57011, 2), (57011,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_probs.shape, dev_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(probs, labels):\n",
    "\n",
    "    metrics = dict()\n",
    "    metrics['roc_auc'] = roc_auc_score(labels, probs[:, 1])\n",
    "    metrics['aver_pr'] = average_precision_score(labels, probs[:, 1])\n",
    "    metrics['f1'] = max(\n",
    "        [f1_score(y_true=labels, y_pred=(probs[:, 1] > threshold).astype(int))\n",
    "            for threshold in np.linspace(0.001, 0.99)]\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8378391125882765,\n",
       " 'aver_pr': 0.13977888279548203,\n",
       " 'f1': 0.21110555277638818}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resulted metrics\n",
    "\n",
    "calculate_metrics(dev_probs, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_examples = []\n",
    "original_examples = []\n",
    "\n",
    "with open('/mnt/chatbot_models2/fursov/texar/examples/text_style_transfer/samples_cropped/val.12') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i % 2 == 0:\n",
    "            original_examples.append(line.strip())\n",
    "        else:\n",
    "            adversarial_examples.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model=model, dataset_reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254243, 1254243)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adversarial_examples), len(original_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_examples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:25<00:00, 499.16it/s]\n"
     ]
    }
   ],
   "source": [
    "original_probs = []\n",
    "for example in tqdm(original_examples[:max_examples]):\n",
    "    original_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:02<00:00, 412.25it/s]\n"
     ]
    }
   ],
   "source": [
    "adversarial_probs = []\n",
    "for example in tqdm(adversarial_examples[:max_examples]):\n",
    "    if example:\n",
    "        adversarial_probs.append(predictor.predict(example)['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_probs = np.array(original_probs)\n",
    "adversarial_probs = np.array(adversarial_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 2), (99677, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_probs.shape, adversarial_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean prob = 0.9868909656191617, median = 0.9957349002361298\n",
      "Original max prob = 1.0, min = 0.02725524827837944\n"
     ]
    }
   ],
   "source": [
    "print(f'Original mean prob = {original_probs[:, 0].mean()}, median = {np.median(original_probs[:, 0])}')\n",
    "print(f'Original max prob = {original_probs[:, 0].max()}, min = {original_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial mean prob = 0.19455415233026777, median = 4.211214036331512e-05\n",
      "Adversarial max prob = 1.0, min = 1.528894633624645e-23\n"
     ]
    }
   ],
   "source": [
    "print(f'Adversarial mean prob = {adversarial_probs[:, 0].mean()}, median = {np.median(adversarial_probs[:, 0])}')\n",
    "print(f'Adversarial max prob = {adversarial_probs[:, 0].max()}, min = {adversarial_probs[:, 0].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
